{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6af31c2-637a-4c84-bcb0-9786b66e808f",
   "metadata": {},
   "source": [
    "# DeLA Interactive Notebook\n",
    "\n",
    "Created by: Maosheng Jiang\n",
    "\n",
    "This notebook is a supplementary educational tool to illustrate how the spatial-regularizer works in the paper: [Decoupled Local Aggregation for Point Cloud Learning](https://arxiv.org/abs/2308.16532)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a616b777-e232-4b64-ba8c-af5aadfc1369",
   "metadata": {},
   "source": [
    "## Preliminaries \n",
    "\n",
    "Traditional local aggregators (e.g. DGCNN, PointNet++) will, at each aggregation layer, recalculate the neighbors in the feature space or in the coordinate space. If a lot of aggregation layers are stacked, then this will become computationally expensive. Decoupled Local Aggregation (DeLA) proposes Decoupled Local Aggregation: we compute and encode the neighbourhood of points beforehand and avoid recomputing this in each successive layer.\n",
    "\n",
    "![Traditional Aggregation vs Decoupled Local Aggregation](local_aggregation.png)\n",
    "\n",
    "In the image above, we can see that in the case of DeLA, we only compute the neighborhood once (which then gets encoded within the point features), and the subsequent layer do not have to recompute the neighborhood again.\n",
    "\n",
    "The downside of this, is that the encoding of the relative distance may degrade deeper into the layers. For that, we employ a spatial regularization term, which essentially trains a small MLP in parallel to keep the encoded relative distance intact within an aggregation layer. This is exactly the technique that we are going to explore in this notebook. For more information about DeLA, please refer to the original paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9714d7ea-2ac7-4643-97f9-c9f47a0ec972",
   "metadata": {},
   "source": [
    "First, let's import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baef8cdb-dc36-4771-86c1-d5fb27d17c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import matplotlib.cm as cm\n",
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32c4f7-1f3b-4f39-a1c3-0e9e2b5209e6",
   "metadata": {},
   "source": [
    "----\n",
    "## Walkthrough example\n",
    "\n",
    "To illustrate the regularization term, we will train a simple point cloud network to classify 2D point clouds of handwritten digits (MNIST). This dataset contains 60000 2D point clouds , each consisting of a maximum of 351 2D points with a corresponding value which specifies how large a point is. The test set contains 10000 2D point clouds. For more information, refer to the kaggle source: https://www.kaggle.com/datasets/cristiangarcia/pointcloudmnist2d/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c5ff68-b27a-4bc2-baf4-8e6e6a9c5627",
   "metadata": {},
   "source": [
    "Now, let's get familiar with the dataset and load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618f3d69-2b96-4c23-a0f7-7ff65e5da444",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = Path(\"archive/train.csv\")\n",
    "TEST_PATH = Path(\"archive/test.csv\")\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    X = df[df.columns[1:]].to_numpy()\n",
    "    y = df[df.columns[0]].to_numpy()\n",
    "\n",
    "    X = X.reshape((X.shape[0], 351, 3))\n",
    "    X = X[:, :, :-1] # Drop the value column (not needed)\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "\n",
    "    # X: [60000, 351, 3], y: [60000, 1]\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "X_train, y_train = preprocess_data(read_data(TRAIN_PATH))\n",
    "X_test, y_test = preprocess_data(read_data(TEST_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63068c0-f97e-474c-a591-782e92368ede",
   "metadata": {},
   "source": [
    "All point clouds have a fixed number of points (351). This is because it is the maximum number of points found in a single point cloud of the dataset. If a point cloud has less than 351 points, then the rest of the points are masked out as -1. So we need to account for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3740428-bd24-44cf-ad40-14bafe25c261",
   "metadata": {},
   "source": [
    "Let's visualize a point cloud!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f9d1a20-8b08-40e8-9e39-d32c385103ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(X_train.shape[0])\n",
    "\n",
    "pc = X_train[idx]\n",
    "\n",
    "# Keep only the real points (where x != -1 and y != -1)\n",
    "pc = pc[(pc[:, 0] != -1) & (pc[:, 1] != -1)]\n",
    "label = y_train[idx].item()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(pc[:, 0], pc[:, 1])\n",
    "plt.title(f\"Example MNIST point cloud of digit {int(label)}\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21c453-608f-4928-affa-77c3d7a1757f",
   "metadata": {},
   "source": [
    "Now we have the MNIST 2D point clouds, let's make the data loader for the train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3957d0e2-d1c1-4285-ad17-588d6864d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        X: [num_samples, 351, 2] \n",
    "        y: [num_samples, 1]\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        pc = self.X[item]\n",
    "        label = self.y[item]\n",
    "\n",
    "        # Keep only the real points (where x != -1 and y != -1)\n",
    "        pc = pc[(pc[:, 0] != -1) & (pc[:, 1] != -1)]\n",
    "\n",
    "        return pc, label\n",
    "\n",
    "\n",
    "# Since the point clouds have variable amount of points, we cannot use default batching.\n",
    "# We need to implement a custom collate_fn which will be passed into the dataloader\n",
    "# to create a custom batch, which is a list of variable point clouds\n",
    "def collate_fn(batch):\n",
    "    coords_list = [item[0] for item in batch]\n",
    "    labels      = [item[1] for item in batch]\n",
    "    return coords_list, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1c00ffa-c529-43bd-b927-dcc112ee5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PointCloudDataset(X_train, y_train)\n",
    "test_ds = PointCloudDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=1, collate_fn=collate_fn, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72426f70-48b3-4d55-8cc5-90499e61239f",
   "metadata": {},
   "source": [
    "---\n",
    "## Model\n",
    "\n",
    "Now we have the dataloaders ready, it is time to define a basic 2D point cloud classification model with 3 local aggregation layers with global max pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fa0bc8-4812-4d51-b05c-993fe93f3ac9",
   "metadata": {},
   "source": [
    "First we precompute the relative distances of the k neighbors of each point. We are using a basic method that first computes for each point the euclidean distance to all other points. In the original DeLA implementation, the authors used an knn algorithm with KD-Trees which is more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cc6e484-b053-4252-99a8-7acc17aa0905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [0, 2],\n",
      "        [1, 3],\n",
      "        [2, 1]])\n",
      "tensor([[[ 0.,  1.],\n",
      "         [ 0.,  2.]],\n",
      "\n",
      "        [[ 0., -1.],\n",
      "         [ 0.,  1.]],\n",
      "\n",
      "        [[ 0., -1.],\n",
      "         [ 0.,  1.]],\n",
      "\n",
      "        [[ 0., -1.],\n",
      "         [ 0., -2.]]])\n"
     ]
    }
   ],
   "source": [
    "def knn_indices(pc, k):\n",
    "    \"\"\"\n",
    "    pc: [N,2] point cloud\n",
    "    returns indices: [N,k] tensor of neighbor indices for each point\n",
    "    \"\"\"\n",
    "    dist = torch.cdist(pc, pc, p=2)\n",
    "    values, indices = torch.topk(dist, k+1, largest=False, dim=-1)\n",
    "\n",
    "    # Remove the index of its own point\n",
    "    return indices[:, 1:]\n",
    "\n",
    "\n",
    "# Sanity check\n",
    "test_pc = torch.tensor([[0., 0.],[0., 1.],[0., 2.],[0., 3.]]) # [N, 2] out test point cloud\n",
    "indices = knn_indices(test_pc, 2) # [N, k] indices of of the neighbors\n",
    "print(indices)\n",
    "rel_dist = test_pc[indices] - test_pc.unsqueeze(1) # [N, k, 2] relative distances for each neighbor\n",
    "print(rel_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c87993-5744-4a90-84b5-4cd9a3aeff45",
   "metadata": {},
   "source": [
    "---\n",
    "## Defining a standard local aggregation layer\n",
    "\n",
    "Now, we will define a standard local aggregation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ff0025d-2fa3-4e41-a78e-cb5faed41c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6587, -0.2376,  0.1579,  0.1271, -0.4543, -0.1646],\n",
       "        [ 0.5284, -0.1272,  0.0682,  0.3469, -0.3305, -0.0605],\n",
       "        [ 0.5008, -0.1615,  0.0847,  0.3579, -0.2915, -0.0425],\n",
       "        [ 0.7406, -0.1816, -0.0659,  0.4541, -0.2540, -0.0453]],\n",
       "       grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LocalAggrLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard local aggregation layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels*2 + 2, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, pc, knn, rel_dist):\n",
    "        \"\"\"\n",
    "        pc: [N, in_channels] point cloud\n",
    "        knn: [N, k] precomputed neighbors indices\n",
    "        rel_dist: [N, k, 2] relative distances\n",
    "        \"\"\"\n",
    "\n",
    "        # A tensor where each point N has the features of its k neighbors\n",
    "        neighbor_feat = pc[knn] # [N, k, in_channels]\n",
    "\n",
    "        # A tensor with features of each point\n",
    "        center_feat = pc.unsqueeze(1).expand_as(neighbor_feat) # [N, k, in_channels]\n",
    "\n",
    "        # A tensor with relative distances of each neighbor to a point\n",
    "        rel_dist = rel_dist # [N, k, 2]\n",
    "\n",
    "        # Now we make up the final feature for each neighbor for message passing: [center_features, neighbor_features, relative_distance]\n",
    "        message_feat = torch.concat([center_feat, neighbor_feat, rel_dist], dim=2) # [N, k, in_channel*2 + 2]\n",
    "\n",
    "        result = self.mlp(message_feat) # [N, k, out_channels]\n",
    "\n",
    "        # Now we aggregate using max (basically a MaxPool)\n",
    "        values, indices = torch.max(result, dim=1)\n",
    "\n",
    "        return values\n",
    "\n",
    "\n",
    "# Sanity check\n",
    "x = LocalAggrLayer(2, 6) # A layer with 2D input and output 6D feature vector\n",
    "test_pc = torch.tensor([[0., 0.],[0., 1.],[0., 2.],[0., 3.]]) # Our test point cloud\n",
    "indices = knn_indices(test_pc, 2) # Calculate the indices of 2 neighbors\n",
    "relative_distances = test_pc[indices] - test_pc.unsqueeze(1) # The relative distances of each neighbor\n",
    "x(torch.tensor([[0., 0.],[0., 1.],[0., 2.],[0., 3.]]), indices, relative_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c9fb2-27a5-46cb-a3c0-937620b85ee1",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Training\n",
    "\n",
    "Now that we have defined a normal aggregation layer, let's start training it on our training set. First we will define the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb502877-f173-4396-9ce6-a0aac7ddff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters will be utilized for both training the normal and the DeLA version\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "in_channels = 2\n",
    "hidden_channels = 16\n",
    "out_channels = 32\n",
    "k = 5\n",
    "classes = 10\n",
    "learning_rate = 0.001\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb2d2d-200b-4cc5-8259-4b27b9b628ca",
   "metadata": {},
   "source": [
    "Below, we will define our complete network that will predict the MNIST 2D point clouds. Notice that our network consists of 3 of our previously defined local aggregation layers. After applying a global max pool layer (just like in PointNet) we pass it through a fully connected layer to produce our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c724bd2a-d913-42a6-a3c9-0741ea430977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.layer1 = LocalAggrLayer(in_channels, hidden_channels)\n",
    "        self.layer2 = LocalAggrLayer(hidden_channels, hidden_channels)\n",
    "        self.layer3 = LocalAggrLayer(hidden_channels, out_channels)\n",
    "        self.fc = nn.Linear(out_channels, classes)\n",
    "\n",
    "    \n",
    "    def forward(self, pc, knn, rel_dist):\n",
    "        \"\"\"\n",
    "        pc: [N, 2] point cloud\n",
    "        knn: [N, k] precomputed neighbors indices\n",
    "        rel_dist: [N, k, 2] relative distances\n",
    "        \"\"\"\n",
    "        x = self.layer1(pc, knn, rel_dist) # [N, in_channels]\n",
    "        x = self.layer2(x, knn, rel_dist) # [N, hidden_channels]\n",
    "        x = self.layer3(x, knn, rel_dist) # [N, out_channels]\n",
    "        \n",
    "        # Apply global max pooling\n",
    "        x, _ = torch.max(x, dim=0)\n",
    "\n",
    "        # Final classification head\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd72af7-877f-463f-85dc-ebb6bad8c7ab",
   "metadata": {},
   "source": [
    "Then, we define the model, optimizer, and criterion and run the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "242f5888-e2a2-436e-8d1b-098bb0b7e23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] 3200/60000, Accuracy: 0.30\n",
      "Epoch [1] 6400/60000, Accuracy: 0.44\n",
      "Epoch [1] 9600/60000, Accuracy: 0.52\n",
      "Epoch [1] 12800/60000, Accuracy: 0.57\n",
      "Epoch [1] 16000/60000, Accuracy: 0.61\n",
      "Epoch [1] 19200/60000, Accuracy: 0.64\n",
      "Epoch [1] 22400/60000, Accuracy: 0.67\n",
      "Epoch [1] 25600/60000, Accuracy: 0.69\n",
      "Epoch [1] 28800/60000, Accuracy: 0.71\n",
      "Epoch [1] 32000/60000, Accuracy: 0.73\n",
      "Epoch [1] 35200/60000, Accuracy: 0.75\n",
      "Epoch [1] 38400/60000, Accuracy: 0.76\n",
      "Epoch [1] 41600/60000, Accuracy: 0.77\n",
      "Epoch [1] 44800/60000, Accuracy: 0.78\n",
      "Epoch [1] 48000/60000, Accuracy: 0.79\n",
      "Epoch [1] 51200/60000, Accuracy: 0.80\n",
      "Epoch [1] 54400/60000, Accuracy: 0.80\n",
      "Epoch [1] 57600/60000, Accuracy: 0.81\n",
      "Epoch [1/1], Loss: 0.5512, Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "normal_model = GNN(in_channels, hidden_channels, out_channels).to(device)\n",
    "optimizer = optim.Adam(normal_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    normal_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for points, labels in train_loader:\n",
    "        batch_loss = 0.0\n",
    "        correct_in_batch = 0\n",
    "\n",
    "        # Iterate over each point cloud in the batch\n",
    "        for i in range(len(points)):\n",
    "            pc = points[i].to(device)\n",
    "            label = labels[i].to(device)\n",
    "\n",
    "            knn = knn_indices(pc, k)\n",
    "\n",
    "            rel_dist = pc[knn] - pc.unsqueeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = normal_model(pc, knn, rel_dist)     \n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.unsqueeze(0), label.long())\n",
    "            batch_loss += loss\n",
    "            \n",
    "            _, predicted = torch.max(outputs, dim=0)\n",
    "            if predicted == label:\n",
    "                correct_in_batch += 1\n",
    "\n",
    "        # Track statistics\n",
    "        running_loss += batch_loss\n",
    "        correct += correct_in_batch\n",
    "        total += len(points)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print intermediary results each 3200 instances\n",
    "        if total % 3200 == 0:   \n",
    "            print(f\"Epoch [{epoch+1}] {total}/60000, Accuracy: {correct/total:.2f}\")\n",
    "\n",
    "    # Print statistics after each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {correct/total:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce745021-2bf0-464d-ba74-8fa9aa1b9aba",
   "metadata": {},
   "source": [
    "---\n",
    "## Implementing Decoupled Local Aggregation version\n",
    "\n",
    "Now as we have seen how a standard local aggregation works, we will move on to the most important part of this notebook: DeLA. As mentioned, the downside is the requirement of feeding the relative distances in each layer. DeLA proposes a different way of local aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64292434-96c4-4436-b71a-74703c675cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0128,  0.3830,  0.3114, -0.3036,  0.6462,  0.7941],\n",
       "        [ 0.0431,  0.1736,  0.2236, -0.3268,  0.4065,  0.6131],\n",
       "        [-0.1999,  0.1210,  0.0849, -0.6127,  0.5760,  0.5933],\n",
       "        [-0.2922,  0.0588,  0.0111, -0.7043,  0.3627,  0.5389]],\n",
       "       grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoupledLocalAggrLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoupled local aggregation layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # Feature aggregation MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels*2, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.cor_head_hidden_dim = 16\n",
    "\n",
    "        # Prediction MLP for predicting relative coordinates\n",
    "        self.pred_mlp = nn.Sequential(\n",
    "            nn.Linear(out_channels, self.cor_head_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.cor_head_hidden_dim, 2)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, xyz, knn, rel_dist):\n",
    "        \"\"\"\n",
    "        xyz: [N, in_channels] point cloud\n",
    "        knn: [N, k] precomputed neighbors indices\n",
    "        rel_dist: [N, k, 2] relative distances\n",
    "        \"\"\"\n",
    "\n",
    "        # A tensor where each point N has the features of its k neighbors\n",
    "        neighbor_feat = xyz[knn] # [N, k, in_channels]\n",
    "\n",
    "        # A tensor with features of each point\n",
    "        center_feat = xyz.unsqueeze(1).expand_as(neighbor_feat) # [N, k, in_channels]\n",
    "\n",
    "        # Now we make up the final feature for each neighbor for message passing: [center_features, neighbor_features]\n",
    "        message_feat = torch.concat([center_feat, neighbor_feat], dim=2) # [N, k, in_channel*2]\n",
    "\n",
    "        result = self.mlp(message_feat) # [N, k, out_channels]\n",
    "        \n",
    "        # Regularization\n",
    "        if self.training:\n",
    "            pred_rel = self.pred_mlp(result) # Outputs the predicted relative distance between each center node and neighbor: [N, k, 2] \n",
    "            reg_loss = nn.functional.mse_loss(pred_rel, rel_dist) # Compare the prediction with ground truth\n",
    "        else:\n",
    "            reg_loss = 0\n",
    "        \n",
    "        # Now we aggregate using max (basically a MaxPool)\n",
    "        values, indices = torch.max(result, dim=1)\n",
    "\n",
    "        return values, reg_loss\n",
    "\n",
    "\n",
    "# Sanity check\n",
    "x = LocalAggrLayer(2, 6) # A layer with 2D input and output 6D feature vector\n",
    "test_pc = torch.tensor([[0., 0.],[0., 1.],[0., 2.],[0., 3.]]) # Our test point cloud\n",
    "indices = knn_indices(test_pc, 2) # Calculate the indices of 2 neighbors\n",
    "relative_distances = test_pc[indices] - test_pc.unsqueeze(1) # The relative distances of each neighbor\n",
    "x(torch.tensor([[0., 0.],[0., 1.],[0., 2.],[0., 3.]]), indices, relative_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea70910-2719-499f-b9e7-25225d7b4cd7",
   "metadata": {},
   "source": [
    "Our complete network to predict the 2D MNIST point clouds is given below and looks identical to the one before. The only difference is that each layer returns the regularization loss of the prediction of relative distances. This distance must be returned by the network to perform backprop. *Note: Because we have a simple 3 layer network, I hardcoded the total regularization loss as the sum of the three, one could simply add the losses dynamically to use more layers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d42fc1f8-3ec1-4b8b-83fb-9ec99a47f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeLAGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.layer1 = DecoupledLocalAggrLayer(in_channels, hidden_channels)\n",
    "        self.layer2 = DecoupledLocalAggrLayer(hidden_channels, hidden_channels)\n",
    "        self.layer3 = DecoupledLocalAggrLayer(hidden_channels, out_channels)\n",
    "        self.fc = nn.Linear(out_channels, classes)\n",
    "\n",
    "    \n",
    "    def forward(self, xyz, knn, rel_dist):\n",
    "        x, reg_loss1 = self.layer1(xyz, knn, rel_dist)\n",
    "        x, reg_loss2 = self.layer2(x, knn, rel_dist)\n",
    "        x, reg_loss3 = self.layer3(x, knn, rel_dist)\n",
    "        \n",
    "        # Apply global max pooling\n",
    "        x, _ = torch.max(x, dim=0)\n",
    "\n",
    "        # Final classification head\n",
    "        x = self.fc(x)\n",
    "\n",
    "        total_reg_loss = reg_loss1 + reg_loss2 + reg_loss3\n",
    "\n",
    "        return x, total_reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a07de22-8c1b-43ab-b7b7-9f00fd6387cc",
   "metadata": {},
   "source": [
    "Finally, we train the DeLA version of our model using the same hyperparameters as before, so make sure you have ran the cell with the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c7b4c036-3bb8-421b-998d-cc4147ca3ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] 3200/60000, Accuracy: 0.20\n",
      "Epoch [1] 6400/60000, Accuracy: 0.33\n",
      "Epoch [1] 9600/60000, Accuracy: 0.40\n",
      "Epoch [1] 12800/60000, Accuracy: 0.44\n",
      "Epoch [1] 16000/60000, Accuracy: 0.47\n",
      "Epoch [1] 19200/60000, Accuracy: 0.50\n",
      "Epoch [1] 22400/60000, Accuracy: 0.53\n",
      "Epoch [1] 25600/60000, Accuracy: 0.55\n",
      "Epoch [1] 28800/60000, Accuracy: 0.57\n",
      "Epoch [1] 32000/60000, Accuracy: 0.60\n",
      "Epoch [1] 35200/60000, Accuracy: 0.61\n",
      "Epoch [1] 38400/60000, Accuracy: 0.63\n",
      "Epoch [1] 41600/60000, Accuracy: 0.65\n",
      "Epoch [1] 44800/60000, Accuracy: 0.66\n",
      "Epoch [1] 48000/60000, Accuracy: 0.67\n",
      "Epoch [1] 51200/60000, Accuracy: 0.68\n",
      "Epoch [1] 54400/60000, Accuracy: 0.70\n",
      "Epoch [1] 57600/60000, Accuracy: 0.71\n",
      "Epoch [1/1], Loss: 0.8812, Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "dela_model = DeLAGNN(in_channels, hidden_channels, out_channels).to(device)\n",
    "optimizer = optim.Adam(dela_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    dela_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for points, labels in train_loader:\n",
    "        batch_loss = 0.0\n",
    "        correct_in_batch = 0\n",
    "\n",
    "        # Iterate over each point cloud in the batch\n",
    "        for i in range(len(points)):\n",
    "            point_cloud = points[i].to(device)\n",
    "            label = labels[i].to(device)\n",
    "\n",
    "            knn = knn_indices(point_cloud, k_neighbors)\n",
    "\n",
    "            rel_dist = point_cloud[knn] - point_cloud.unsqueeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, reg_loss = dela_model(point_cloud, knn, rel_dist)     \n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.unsqueeze(0), label.long())\n",
    "            batch_loss += loss + reg_loss\n",
    "            \n",
    "            _, predicted = torch.max(outputs, dim=0)\n",
    "            if predicted == label:\n",
    "                correct_in_batch += 1\n",
    "\n",
    "        # Track statistics\n",
    "        running_loss += batch_loss\n",
    "        correct += correct_in_batch\n",
    "        total += len(points)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print intermediary results each 3200 instances\n",
    "        if total % 3200 == 0:   \n",
    "            print(f\"Epoch [{epoch+1}] {total}/60000, Accuracy: {correct/total:.2f}\")\n",
    "\n",
    "    # Print statistics after each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {correct/total:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43c676ae-bf2a-4721-bb59-c6e768016ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on normal model: 88.45%\n",
      "Test accuracy on DeLA model: 88.58%\n"
     ]
    }
   ],
   "source": [
    "def testNormalGNN():\n",
    "    \"\"\"\n",
    "    Validate the accuracy of the normal model on the testset\n",
    "    \"\"\"\n",
    "    k_neighbors = 5\n",
    "    normal_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for points, labels in test_loader:\n",
    "            for i in range(len(points)):\n",
    "                point_cloud = points[i].to(device) # [N, 2]\n",
    "                label = labels[i].to(device)\n",
    "    \n",
    "                knn = knn_indices(point_cloud, k_neighbors) # [N, k]\n",
    "                rel_dist = point_cloud[knn] - point_cloud.unsqueeze(1) # [N, k, 2]\n",
    "    \n",
    "                outputs = normal_model(point_cloud, knn, rel_dist)\n",
    "    \n",
    "                _, predicted = torch.max(outputs, dim=0)\n",
    "                if predicted == label:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "    \n",
    "    print(f'Test accuracy on normal model: {100 * correct / total:.2f}%')\n",
    "\n",
    "    \n",
    "def testDeLAGNN():\n",
    "    \"\"\"\n",
    "    Validate the accuracy of the DeLA model on the testset\n",
    "    \"\"\"\n",
    "    k_neighbors = 5\n",
    "    dela_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for points, labels in test_loader:\n",
    "            for i in range(len(points)):\n",
    "                point_cloud = points[i].to(device) # [N, 2]\n",
    "                label = labels[i].to(device)\n",
    "    \n",
    "                knn = knn_indices(point_cloud, k_neighbors) # [N, k]\n",
    "                rel_dist = point_cloud[knn] - point_cloud.unsqueeze(1) # [N, k, 2]\n",
    "    \n",
    "                outputs, _ = dela_model(point_cloud, knn, rel_dist)\n",
    "    \n",
    "                _, predicted = torch.max(outputs, dim=0)\n",
    "                if predicted == label:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "    \n",
    "    print(f'Test accuracy on DeLA model: {100 * correct / total:.2f}%')\n",
    "\n",
    "testNormalGNN()\n",
    "testDeLAGNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e644953-ed8b-42a2-aab1-544ff2e3f691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c716ab9-0366-4667-9963-61975071b694",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualizing the predictive performance of DeLA\n",
    "In the cell below, we can predict visualize the relative distance predictions of the prediction MLP inside each layer. As can be seen, the predictions are quite reasonable, even in deeper layers.\n",
    "\n",
    "You can use the provided slider to select a particular point in the point cloud. If you want to test it on a new random 2D MNIST point cloud, just rerun the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "80fcd567-994e-4fe5-a703-30b671d6ec18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ceab1ae03840d19d36d17953004d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=158), Output()), _dom_classes=('widget-interact'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dela_model.eval()\n",
    "\n",
    "coords, labels = next(iter(test_loader))\n",
    "pc = coords[0].to(device) # [N, 2]\n",
    "label = labels[0].item()\n",
    "\n",
    "\n",
    "k = 5\n",
    "knn = knn_indices(pc, k)\n",
    "\n",
    "\n",
    "neighbor_feat = pc[knn] # [N, k, 2]\n",
    "center_feat = pc.unsqueeze(1).expand_as(neighbor_feat) # [N, k, 2]\n",
    "center_coords = center_feat\n",
    "message_feat = torch.cat([center_feat, neighbor_feat], dim=2) # [N, k, 4]\n",
    "\n",
    "pred_feat = dela_model.layer1.mlp(message_feat) # [N, k, hidden_channels=16]\n",
    "pred_rel = dela_model.layer1.pred_mlp(pred_feat) # [N, k, 2]\n",
    "pred_coords = center_coords + pred_rel # [N, k, 2]\n",
    "\n",
    "pc_np = pc.cpu().numpy()\n",
    "pred_coords_np = pred_coords.cpu().detach().numpy()\n",
    "knn_np = knn.cpu().numpy()\n",
    "\n",
    "\n",
    "def show_pred(i):\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.scatter(pc_np[:, 0], pc_np[:, 1], c='lightgray', label='Point cloud')\n",
    "    plt.scatter(pc_np[i, 0], pc_np[i, 1], c='red', label='Center point', s=60)\n",
    "    \n",
    "    colors = cm.tab10(np.linspace(0, 1, k))[:, :3]\n",
    "    darker_colors = colors * 0.2\n",
    "    \n",
    "    for j in range(k):\n",
    "        neighbor_idx = knn_np[i, j]\n",
    "        true_neighbor = pc_np[neighbor_idx]\n",
    "        predicted_neighbor = pred_coords_np[i, j]\n",
    "    \n",
    "        plt.scatter(true_neighbor[0], true_neighbor[1], color=colors[j], label=f'True neighbor {j+1}', s=30)\n",
    "        plt.scatter(predicted_neighbor[0], predicted_neighbor[1], color=darker_colors[j], marker='x', s=30, label=f'Predicted neighbor {j+1}')\n",
    "\n",
    "        # Plot lines\n",
    "        plt.plot([pc_np[i, 0], true_neighbor[0]], [pc_np[i, 1], true_neighbor[1]], color=colors[j], linestyle='--', linewidth=1)\n",
    "        plt.plot([pc_np[i, 0], predicted_neighbor[0]], [pc_np[i, 1], predicted_neighbor[1]], color=darker_colors[j], linestyle='-', linewidth=1)\n",
    "\n",
    "    plt.title(f\"Predicted neighbor positions, label: {int(label)}\")\n",
    "    plt.legend(\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(0.5, -0.1),\n",
    "        ncol=3,\n",
    "    )\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "interact(show_pred, i=IntSlider(min=0, max=pc.shape[0]-1, step=1, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8feacf-3f16-4732-a382-22653e9af58c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Please install anywidget to use the FigureWidget class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m initial_colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create a FigureWidget scatter\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigureWidget(\n\u001b[1;32m     12\u001b[0m     data\u001b[38;5;241m=\u001b[39m[go\u001b[38;5;241m.\u001b[39mScatter(\n\u001b[1;32m     13\u001b[0m         x\u001b[38;5;241m=\u001b[39mx, \n\u001b[1;32m     14\u001b[0m         y\u001b[38;5;241m=\u001b[39my, \n\u001b[1;32m     15\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarkers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m         marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(color\u001b[38;5;241m=\u001b[39minitial_colors, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     17\u001b[0m     )],\n\u001b[1;32m     18\u001b[0m     layout\u001b[38;5;241m=\u001b[39mgo\u001b[38;5;241m.\u001b[39mLayout(\n\u001b[1;32m     19\u001b[0m         title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClick a point to toggle its color\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m         dragmode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpan\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m scatter \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Define the click callback\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Seminar/lib/python3.11/site-packages/plotly/missing_anywidget.py:13\u001b[0m, in \u001b[0;36mFigureWidget.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install anywidget to use the FigureWidget class\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Please install anywidget to use the FigureWidget class"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Generate some random data\n",
    "np.random.seed(42)\n",
    "x = np.random.randn(30)\n",
    "y = np.random.randn(30)\n",
    "initial_colors = ['blue'] * len(x)\n",
    "\n",
    "# Create a FigureWidget scatter\n",
    "fig = go.FigureWidget(\n",
    "    data=[go.Scatter(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        mode='markers',\n",
    "        marker=dict(color=initial_colors, size=10)\n",
    "    )],\n",
    "    layout=go.Layout(\n",
    "        title=\"Click a point to toggle its color\",\n",
    "        dragmode='pan'\n",
    "    )\n",
    ")\n",
    "\n",
    "scatter = fig.data[0]\n",
    "\n",
    "# Define the click callback\n",
    "def on_point_click(trace, points, state):\n",
    "    # Copy the current colors\n",
    "    colors = list(trace.marker.color)\n",
    "    # Toggle each clicked point\n",
    "    for i in points.point_inds:\n",
    "        colors[i] = 'red' if colors[i] == 'blue' else 'blue'\n",
    "    # Update the trace\n",
    "    trace.marker.color = colors\n",
    "\n",
    "# Bind the callback\n",
    "scatter.on_click(on_point_click)\n",
    "\n",
    "# Display\n",
    "fig\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
